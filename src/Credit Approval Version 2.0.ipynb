{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv1D, MaxPooling1D\n",
    "# from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from the data file\n",
    "Column names also added\n",
    "Probable colomn names\n",
    "Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income and ApprovalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.25</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.04</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.29</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2      A3 A4 A5  A6  A7    A8 A9 A10  A11 A12 A13    A14  A15  \\\n",
       "0    b  30.83   0.000  u  g   w   v  1.25  t   t    1   f   g  00202    0   \n",
       "1    a  58.67   4.460  u  g   q   h  3.04  t   t    6   f   g  00043  560   \n",
       "2    a  24.50   0.500  u  g   q   h  1.50  t   f    0   f   g  00280  824   \n",
       "3    b  27.83   1.540  u  g   w   v  3.75  t   t    5   t   g  00100    3   \n",
       "4    b  20.17   5.625  u  g   w   v  1.71  t   f    0   f   s  00120    0   \n",
       "..  ..    ...     ... .. ..  ..  ..   ... ..  ..  ...  ..  ..    ...  ...   \n",
       "685  b  21.08  10.085  y  p   e   h  1.25  f   f    0   f   g  00260    0   \n",
       "686  a  22.67   0.750  u  g   c   v  2.00  f   t    2   t   g  00200  394   \n",
       "687  a  25.25  13.500  y  p  ff  ff  2.00  f   t    1   t   g  00200    1   \n",
       "688  b  17.92   0.205  u  g  aa   v  0.04  f   f    0   f   g  00280  750   \n",
       "689  b  35.00   3.375  u  g   c   h  8.29  f   f    0   t   g  00000    0   \n",
       "\n",
       "    label  \n",
       "0       +  \n",
       "1       +  \n",
       "2       +  \n",
       "3       +  \n",
       "4       +  \n",
       "..    ...  \n",
       "685     -  \n",
       "686     -  \n",
       "687     -  \n",
       "688     -  \n",
       "689     -  \n",
       "\n",
       "[690 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['A1', 'A2','A3','A4', 'A5', 'A6', 'A7', 'A8','A9', 'A10', 'A11','A12', 'A13', 'A14', 'A15', 'label']\n",
    "df = pd.read_csv('../data/crx.data', names=columns)\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>1017.385507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>5210.102598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>395.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A3          A8        A11            A15\n",
       "count  690.000000  690.000000  690.00000     690.000000\n",
       "mean     4.758725    2.223406    2.40000    1017.385507\n",
       "std      4.978163    3.346513    4.86294    5210.102598\n",
       "min      0.000000    0.000000    0.00000       0.000000\n",
       "25%      1.000000    0.165000    0.00000       0.000000\n",
       "50%      2.750000    1.000000    0.00000       5.000000\n",
       "75%      7.207500    2.625000    3.00000     395.500000\n",
       "max     28.000000   28.500000   67.00000  100000.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      678 non-null    object \n",
      " 1   A2      678 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      684 non-null    object \n",
      " 4   A5      684 non-null    object \n",
      " 5   A6      681 non-null    object \n",
      " 6   A7      681 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     677 non-null    object \n",
      " 14  A15     690 non-null    int64  \n",
      " 15  label   690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove missing values\n",
    "+ Replace '?' with NaN\n",
    "+ Then replace all numerical NAN values with the mean\n",
    "+ Replace categorical values with the most occured element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      678 non-null    object \n",
      " 1   A2      678 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      684 non-null    object \n",
      " 4   A5      684 non-null    object \n",
      " 5   A6      681 non-null    object \n",
      " 6   A7      681 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     677 non-null    object \n",
      " 14  A15     690 non-null    int64  \n",
      " 15  label   690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "NaN values: 67\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    object \n",
      " 1   A2      690 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    object \n",
      " 4   A5      690 non-null    object \n",
      " 5   A6      690 non-null    object \n",
      " 6   A7      690 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     690 non-null    object \n",
      " 14  A15     690 non-null    int64  \n",
      " 15  label   690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(df.tail(20))\n",
    "print(df.info())\n",
    "print(\"NaN values: {}\".format(df.isnull().values.sum()))\n",
    "df = df.fillna(df.mean())\n",
    "# print(df.tail(20))\n",
    "# print(\"NaN values: {}\".format(df.isnull().values.sum()))\n",
    "df['A1'].value_counts()\n",
    "\n",
    "for col in df.columns:\n",
    "    # Check if the column is of object type\n",
    "    if df[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        df[col] = df[col].fillna(df[col].value_counts().index[0])\n",
    "print(df.info())       \n",
    "print(\"NaN values: {}\".format(df.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert none neumeric data into neumeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>4.460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1   A2     A3  A4  A5  A6  A7    A8  A9  A10  A11  A12  A13  A14  A15  \\\n",
       "0   1  156  0.000   1   0  12   7  1.25   1    1    1    0    0   68    0   \n",
       "1   0  328  4.460   1   0  10   3  3.04   1    1    6    0    0   11  560   \n",
       "2   0   89  0.500   1   0  10   3  1.50   1    0    0    0    0   96  824   \n",
       "3   1  125  1.540   1   0  12   7  3.75   1    1    5    1    0   31    3   \n",
       "4   1   43  5.625   1   0  12   7  1.71   1    0    0    0    2   37    0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in df.columns:\n",
    "    # Compare if the dtype is object\n",
    "    if df[col].dtype=='object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        df[col]=le.fit_transform(df[col])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the features that are not usable\n",
    "As we have a good understanding about the data\n",
    "\n",
    "1. Gender\n",
    "2. Age\n",
    "3. Debt\n",
    "4. Married\n",
    "5. BankCustomer\n",
    "6. EducationLevel\n",
    "7. Ethnicity\n",
    "8. YearsEmployed\n",
    "9. PriorDefault\n",
    "10. Employed\n",
    "11. CreditScore\n",
    "12. DriversLicense\n",
    "13. Citizen\n",
    "14. ZipCode\n",
    "15. Income\n",
    "16. ApprovalStatus\n",
    "\n",
    "Looking at these data its clear that \n",
    "+ Zipcode\n",
    "+ Drivers License\n",
    "\n",
    "IS not relevent for this classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    int64  \n",
      " 1   A2      690 non-null    int64  \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    int64  \n",
      " 4   A5      690 non-null    int64  \n",
      " 5   A6      690 non-null    int64  \n",
      " 6   A7      690 non-null    int64  \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    int64  \n",
      " 9   A10     690 non-null    int64  \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A13     690 non-null    int64  \n",
      " 12  A15     690 non-null    int64  \n",
      " 13  label   690 non-null    int64  \n",
      "dtypes: float64(2), int64(12)\n",
      "memory usage: 75.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['A12', 'A14'],axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize all the neumerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690,)\n",
      "(690, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dfn = df.values\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X,y = dfn[:,0:13], dfn[:,13]\n",
    "\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "print(y.shape)\n",
    "print(rescaledX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "It takes input as \n",
    "+ No of dense neurons\n",
    "+ Activation functions\n",
    "+ Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_v2(layer_info):\n",
    "    inputs=tf.keras.Input(shape=13)\n",
    "    x = inputs\n",
    "    for li in layer_info['layers']:\n",
    "        print(li)\n",
    "        x = tf.keras.layers.Dense(li[0], activation=li[1], kernel_regularizer=li[2])(x)\n",
    "                                  \n",
    "    output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    if layer_info['verbose'] == 1:\n",
    "        logging.info(model.summary())\n",
    "\n",
    "    # Compile model\n",
    "    opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer=layer_info['optimizer'], loss=layer_info['loss'], metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold cross validation\n",
    "This will try 5 fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def train_with_kfold(model):\n",
    "    n_folds = 5\n",
    "    f1_score_list = []\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    for train_ix, test_ix in kfold.split(rescaledX):\n",
    "        X_train, X_test, y_train, y_test = rescaledX[train_ix],rescaledX[test_ix], y[train_ix], y[test_ix]\n",
    "        history = model_v2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "        y_pred = np.where(model_v2.predict(X_test) > 0.5, 1, 0)\n",
    "        f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "        f1_score_list.append(float(\"{:2.2f}\".format(f1*100)))\n",
    "        \n",
    "    print(\"F1 score: {}\".format(f1_score_list))\n",
    "    print(\"Average F1: {:.3f}\".format(np.mean(f1_score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 300.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Average F1: {:2.3f}\".format(np.mean([1,2,3,4,5])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0da0188dd0>]\n",
      "F1 score: [89.13, 88.1, 84.0, 81.06, 88.37]\n",
      "Average F1: 86.132\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d58593250>]\n",
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d585936d0>]\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 106\n",
      "Trainable params: 106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "F1 score: ['89.13', '88.10', '84.74', '82.55', '86.95']\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)],\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d346c8390>]\n",
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d346c8f10>]\n",
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d346c8710>]\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 136\n",
      "Trainable params: 136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "F1 score: ['87.68', '88.10', '86.89', '80.31', '87.63']\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)],\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)],\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f0e1323f5f0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d346c8250>]\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "F1 score: ['87.68', '88.10', '83.31', '81.84', '89.12']\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function softmax_v2 at 0x7f0e11b9f9e0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0da0246bd0>]\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "F1 score: ['87.68', '88.82', '85.46', '80.35', '88.37']\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.softmax, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function elu at 0x7f0e132edb90>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d347cf4d0>]\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "F1 score: ['87.68', '88.10', '84.04', '81.10', '87.63']\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.elu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu6 at 0x7f0e11b9f680>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d583742d0>]\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 5)                 70        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 76\n",
      "Trainable params: 76\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "F1 score: ['89.13', '87.33', '84.74', '81.06', '87.63']\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu6, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f0e11b9f710>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d3438b850>]\n",
      "F1 score: [88.4, 88.1, 83.31, 81.84, 86.2]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-e257e3098d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m            }\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_with_kfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-48116a263f19>\u001b[0m in \u001b[0;36mtrain_with_kfold\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mf1_score_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:2.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1 score: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average F1: {2:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different Losses - [Probabilistic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f0e11b9f710>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d585d35d0>]\n",
      "F1 score: [86.95, 88.1, 84.74, 81.1, 87.65]\n",
      "Average F1: 85.708\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f0e11b9f710>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d5828b410>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [31.34, 28.12, 29.95, 32.02, 32.35]\n",
      "Average F1: 30.756\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"sparse_categorical_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f0e11b9f710>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0ddc0f1d90>]\n",
      "F1 score: [89.12, 88.04, 84.76, 83.31, 89.12]\n",
      "Average F1: 86.870\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"poisson\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f0e11b9f710>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d25fe17d0>]\n",
      "F1 score: [20.98, 27.29, 24.21, 32.58, 30.42]\n",
      "Average F1: 27.096\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"categorical_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f0e11b9f710>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f0d344946d0>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:187 __call__\n        self._build(y_pred)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:140 _build\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/util/nest.py:617 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/util/nest.py:617 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:264 _get_loss_object\n        loss = losses_mod.get(loss)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1857 get\n        return deserialize(identifier)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1835 deserialize\n        printable_module_name='loss function')\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:392 deserialize_keras_object\n        raise ValueError('Unknown ' + printable_module_name + ':' + object_name)\n\n    ValueError: Unknown loss function:kl_divergence\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-20eb219de794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m            }\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_v2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_with_kfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-125-ed9bc7da4d34>\u001b[0m in \u001b[0;36mtrain_with_kfold\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescaledX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescaledX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrescaledX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_ix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Environments/py376/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:187 __call__\n        self._build(y_pred)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:140 _build\n        self._losses = nest.map_structure(self._get_loss_object, self._losses)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/util/nest.py:617 map_structure\n        structure[0], [func(*x) for x in entries],\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/util/nest.py:617 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:264 _get_loss_object\n        loss = losses_mod.get(loss)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1857 get\n        return deserialize(identifier)\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1835 deserialize\n        printable_module_name='loss function')\n    /home/dulanj/Environments/py376/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py:392 deserialize_keras_object\n        raise ValueError('Unknown ' + printable_module_name + ':' + object_name)\n\n    ValueError: Unknown loss function:kl_divergence\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, tf.keras.regularizers.l2(0)]\n",
    "           ],\n",
    "            \"loss\": \"kl_divergence\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "  \n",
    "    if verbose:\n",
    "        print('Network configuration ',neuronCountInEachLayer)\n",
    "    model.add(tf.keras.layers.Dense(neuronCountInEachLayer[0], input_dim=13, activation = activationFuncEachLayer[0], kernel_regularizer=regularizerFunc)) # First Layer\n",
    "    \n",
    "    for x in range(1, depthOfNetwork-1):\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(neuronCountInEachLayer[x], activation = activationFuncEachLayer[x],kernel_regularizer=regularizerFunc))         # Second layer onwards\n",
    " \n",
    "    model.add(tf.keras.layers.Dense(neuronCountInEachLayer[depthOfNetwork-1], activation = activationFuncEachLayer[depthOfNetwork-1]))  # Output layer\n",
    "    \n",
    "    model.compile(loss = lossFunction , optimizer = 'adam' , metrics = ['accuracy'] ) \n",
    "        \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "def evaluateTheModel(verbose=False):\n",
    "    n_split=5\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index,test_index in StratifiedKFold(n_split).split(X, y):      # StratifiedKFold, KFold\n",
    "        x_train,x_test=X[train_index],X[test_index]\n",
    "        y_train,y_test=y[train_index],y[test_index]\n",
    "\n",
    "        model=create_model(verbose)\n",
    "        model.fit(x_train, y_train,epochs=100, verbose=0)\n",
    "        evaluationMetrics = model.evaluate(x_test,y_test, verbose=0)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Model evaluation ',evaluationMetrics)   # This returns metric values for the evaluation\n",
    "\n",
    "        y_pred = np.where(model.predict(x_test) > 0.5, 1, 0)\n",
    "        print(model.predict(x_test))\n",
    "        f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "\n",
    "        if verbose:\n",
    "            print('F1 score is ', f1)\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluateTheModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9f9644584a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mregularizerFunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# try l1 and l2 with different lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mevaluateTheModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluateTheModel' is not defined"
     ]
    }
   ],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [2, 1]                                 # try different depth and width\n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']            # try values relu, sigmoid, talh\n",
    "lossFunction = 'binary_crossentropy'                                # try values binary_crossentropy, mean_squared_error\n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                       # try l1 and l2 with different lambda\n",
    "\n",
    "evaluateTheModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
