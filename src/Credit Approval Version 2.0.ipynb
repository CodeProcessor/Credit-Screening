{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv1D, MaxPooling1D\n",
    "# from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from the data file\n",
    "Column names also added\n",
    "Probable colomn names\n",
    "Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income and ApprovalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.25</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.00</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.04</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.29</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2      A3 A4 A5  A6  A7    A8 A9 A10  A11 A12 A13    A14  A15  \\\n",
       "0    b  30.83   0.000  u  g   w   v  1.25  t   t    1   f   g  00202    0   \n",
       "1    a  58.67   4.460  u  g   q   h  3.04  t   t    6   f   g  00043  560   \n",
       "2    a  24.50   0.500  u  g   q   h  1.50  t   f    0   f   g  00280  824   \n",
       "3    b  27.83   1.540  u  g   w   v  3.75  t   t    5   t   g  00100    3   \n",
       "4    b  20.17   5.625  u  g   w   v  1.71  t   f    0   f   s  00120    0   \n",
       "..  ..    ...     ... .. ..  ..  ..   ... ..  ..  ...  ..  ..    ...  ...   \n",
       "685  b  21.08  10.085  y  p   e   h  1.25  f   f    0   f   g  00260    0   \n",
       "686  a  22.67   0.750  u  g   c   v  2.00  f   t    2   t   g  00200  394   \n",
       "687  a  25.25  13.500  y  p  ff  ff  2.00  f   t    1   t   g  00200    1   \n",
       "688  b  17.92   0.205  u  g  aa   v  0.04  f   f    0   f   g  00280  750   \n",
       "689  b  35.00   3.375  u  g   c   h  8.29  f   f    0   t   g  00000    0   \n",
       "\n",
       "    label  \n",
       "0       +  \n",
       "1       +  \n",
       "2       +  \n",
       "3       +  \n",
       "4       +  \n",
       "..    ...  \n",
       "685     -  \n",
       "686     -  \n",
       "687     -  \n",
       "688     -  \n",
       "689     -  \n",
       "\n",
       "[690 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['A1', 'A2','A3','A4', 'A5', 'A6', 'A7', 'A8','A9', 'A10', 'A11','A12', 'A13', 'A14', 'A15', 'label']\n",
    "df = pd.read_csv('../data/crx.data', names=columns)\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>1017.385507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>5210.102598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>395.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A3          A8        A11            A15\n",
       "count  690.000000  690.000000  690.00000     690.000000\n",
       "mean     4.758725    2.223406    2.40000    1017.385507\n",
       "std      4.978163    3.346513    4.86294    5210.102598\n",
       "min      0.000000    0.000000    0.00000       0.000000\n",
       "25%      1.000000    0.165000    0.00000       0.000000\n",
       "50%      2.750000    1.000000    0.00000       5.000000\n",
       "75%      7.207500    2.625000    3.00000     395.500000\n",
       "max     28.000000   28.500000   67.00000  100000.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      678 non-null    object \n",
      " 1   A2      678 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      684 non-null    object \n",
      " 4   A5      684 non-null    object \n",
      " 5   A6      681 non-null    object \n",
      " 6   A7      681 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     677 non-null    object \n",
      " 14  A15     690 non-null    int64  \n",
      " 15  label   690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove missing values\n",
    "+ Replace '?' with NaN\n",
    "+ Then replace all numerical NAN values with the mean\n",
    "+ Replace categorical values with the most occured element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      678 non-null    object \n",
      " 1   A2      678 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      684 non-null    object \n",
      " 4   A5      684 non-null    object \n",
      " 5   A6      681 non-null    object \n",
      " 6   A7      681 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     677 non-null    object \n",
      " 14  A15     690 non-null    int64  \n",
      " 15  label   690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "NaN values: 67\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    object \n",
      " 1   A2      690 non-null    object \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    object \n",
      " 4   A5      690 non-null    object \n",
      " 5   A6      690 non-null    object \n",
      " 6   A7      690 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     690 non-null    object \n",
      " 14  A15     690 non-null    int64  \n",
      " 15  label   690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(df.tail(20))\n",
    "print(df.info())\n",
    "print(\"NaN values: {}\".format(df.isnull().values.sum()))\n",
    "df = df.fillna(df.mean())\n",
    "# print(df.tail(20))\n",
    "# print(\"NaN values: {}\".format(df.isnull().values.sum()))\n",
    "df['A1'].value_counts()\n",
    "\n",
    "for col in df.columns:\n",
    "    # Check if the column is of object type\n",
    "    if df[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        df[col] = df[col].fillna(df[col].value_counts().index[0])\n",
    "print(df.info())       \n",
    "print(\"NaN values: {}\".format(df.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert none neumeric data into neumeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>4.460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1   A2     A3  A4  A5  A6  A7    A8  A9  A10  A11  A12  A13  A14  A15  \\\n",
       "0   1  156  0.000   1   0  12   7  1.25   1    1    1    0    0   68    0   \n",
       "1   0  328  4.460   1   0  10   3  3.04   1    1    6    0    0   11  560   \n",
       "2   0   89  0.500   1   0  10   3  1.50   1    0    0    0    0   96  824   \n",
       "3   1  125  1.540   1   0  12   7  3.75   1    1    5    1    0   31    3   \n",
       "4   1   43  5.625   1   0  12   7  1.71   1    0    0    0    2   37    0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Iterate over all the values of each column and extract their dtypes\n",
    "for col in df.columns:\n",
    "    # Compare if the dtype is object\n",
    "    if df[col].dtype=='object':\n",
    "    # Use LabelEncoder to do the numeric transformation\n",
    "        df[col]=le.fit_transform(df[col])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the features that are not usable\n",
    "As we have a good understanding about the data\n",
    "\n",
    "1. Gender\n",
    "2. Age\n",
    "3. Debt\n",
    "4. Married\n",
    "5. BankCustomer\n",
    "6. EducationLevel\n",
    "7. Ethnicity\n",
    "8. YearsEmployed\n",
    "9. PriorDefault\n",
    "10. Employed\n",
    "11. CreditScore\n",
    "12. DriversLicense\n",
    "13. Citizen\n",
    "14. ZipCode\n",
    "15. Income\n",
    "16. ApprovalStatus\n",
    "\n",
    "Looking at these data its clear that \n",
    "+ Zipcode\n",
    "+ Drivers License\n",
    "\n",
    "IS not relevent for this classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      690 non-null    int64  \n",
      " 1   A2      690 non-null    int64  \n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      690 non-null    int64  \n",
      " 4   A5      690 non-null    int64  \n",
      " 5   A6      690 non-null    int64  \n",
      " 6   A7      690 non-null    int64  \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    int64  \n",
      " 9   A10     690 non-null    int64  \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A13     690 non-null    int64  \n",
      " 12  A15     690 non-null    int64  \n",
      " 13  label   690 non-null    int64  \n",
      "dtypes: float64(2), int64(12)\n",
      "memory usage: 75.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.drop(['A12', 'A14'],axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize all the neumerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690,)\n",
      "(690, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dfn = df.values\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X,y = dfn[:,0:13], dfn[:,13]\n",
    "\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "print(y.shape)\n",
    "print(rescaledX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "It takes input as \n",
    "+ No of dense neurons\n",
    "+ Activation functions\n",
    "+ Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_v2(layer_info):\n",
    "    inputs=tf.keras.Input(shape=13)\n",
    "    x = inputs\n",
    "    for li in layer_info['layers']:\n",
    "        x = tf.keras.layers.Dense(li[0], activation=li[1], kernel_regularizer=li[2])(x)\n",
    "                                  \n",
    "    output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    if layer_info['verbose'] == 1:\n",
    "        logging.info(model.summary())\n",
    "\n",
    "    # Compile model\n",
    "    opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=layer_info['optimizer'], loss=layer_info['loss'], metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold cross validation\n",
    "This will try 5 fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def train_with_kfold(model):\n",
    "    n_folds = 5\n",
    "    f1_score_list = []\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    for train_ix, test_ix in kfold.split(rescaledX):\n",
    "        X_train, X_test, y_train, y_test = rescaledX[train_ix],rescaledX[test_ix], y[train_ix], y[test_ix]\n",
    "        history = model_v2.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
    "        y_pred = np.where(model_v2.predict(X_test) > 0.5, 1, 0)\n",
    "        f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "        f1_score_list.append(float(\"{:2.2f}\".format(f1*100)))\n",
    "        \n",
    "    print(\"F1 score: {}\".format(f1_score_list))\n",
    "    print(\"Average F1: {:.3f}\".format(np.mean(f1_score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 300.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Average F1: {:2.3f}\".format(np.mean([1,2,3,4,5])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [87.68, 88.1, 86.2, 80.35, 86.91]\n",
      "Average F1: 85.848\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f89a86947a0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f8904795990>]\n",
      "[5, <function relu at 0x7f89a86947a0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f8904195d50>]\n",
      "F1 score: [87.65, 88.76, 85.43, 82.48, 89.08]\n",
      "Average F1: 86.680\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, None],\n",
    "    [5, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f89a86947a0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f890469b6d0>]\n",
      "[5, <function relu at 0x7f89a86947a0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f890469bf50>]\n",
      "[5, <function relu at 0x7f89a86947a0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f890469bf90>]\n",
      "F1 score: [89.12, 87.33, 85.4, 81.72, 86.14]\n",
      "Average F1: 85.942\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, None],\n",
    "    [5, tf.nn.relu, None],\n",
    "    [5, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different number of neurons\n",
    "5,10,15,20,25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [88.4, 87.33, 85.43, 81.81, 89.1]\n",
      "Average F1: 86.414\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, None],\n",
    "    [5, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [86.91, 91.71, 85.31, 83.23, 89.8]\n",
      "Average F1: 87.392\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [10, tf.nn.relu, None],\n",
    "    [10, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [89.08, 90.14, 88.29, 84.6, 89.82]\n",
      "Average F1: 88.386\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [15, tf.nn.relu, None],\n",
    "    [15, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [89.03, 90.93, 89.72, 82.52, 90.54]\n",
      "Average F1: 88.548\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [20, tf.nn.relu, None],\n",
    "    [20, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [88.32, 90.2, 90.43, 83.23, 89.82]\n",
      "Average F1: 88.400\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [25, tf.nn.relu, None],\n",
    "    [25, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [89.03, 89.48, 88.16, 85.36, 92.02]\n",
      "Average F1: 88.810\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [30, tf.nn.relu, None],\n",
    "    [30, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu at 0x7f89a86947a0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f890417c690>]\n",
      "F1 score: [88.4, 88.82, 85.46, 81.84, 85.48]\n",
      "Average F1: 86.000\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function softmax_v2 at 0x7f89a6ff3b90>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f89041c2810>]\n",
      "F1 score: [87.68, 88.82, 87.63, 81.06, 86.89]\n",
      "Average F1: 86.416\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.softmax, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function elu at 0x7f89a8743d40>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f89042d80d0>]\n",
      "F1 score: [88.4, 88.1, 83.31, 81.1, 87.63]\n",
      "Average F1: 85.708\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.elu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function relu6 at 0x7f89a6ff3830>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f890454f0d0>]\n",
      "F1 score: [88.4, 88.1, 85.48, 80.35, 87.66]\n",
      "Average F1: 85.998\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.relu6, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f89a6ff38c0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f89046a72d0>]\n",
      "F1 score: [87.68, 88.87, 84.03, 81.1, 87.66]\n",
      "Average F1: 85.868\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, None]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different Losses - [Probabilistic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f89a6ff38c0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f88e0479490>]\n",
      "F1 score: [87.68, 88.87, 83.31, 81.1, 87.63]\n",
      "Average F1: 85.718\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, None ]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f89a6ff38c0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f89045b1210>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/Environments/py376/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [31.34, 28.12, 29.95, 32.02, 32.35]\n",
      "Average F1: 30.756\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, None]\n",
    "           ],\n",
    "            \"loss\": \"sparse_categorical_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f89a6ff38c0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f89800c7e10>]\n",
      "F1 score: [87.68, 86.55, 84.76, 81.06, 86.89]\n",
      "Average F1: 85.388\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, None ]\n",
    "           ],\n",
    "            \"loss\": \"poisson\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, <function leaky_relu at 0x7f89a6ff38c0>, <tensorflow.python.keras.regularizers.L1L2 object at 0x7f89044b5b10>]\n",
      "F1 score: [59.2, 51.68, 54.65, 49.44, 53.9]\n",
      "Average F1: 53.774\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [5, tf.nn.leaky_relu, None ]\n",
    "           ],\n",
    "            \"loss\": \"categorical_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    " Take the best network you found in Q2 above and retrain it with the addition of\n",
    "regularization to the loss function. Try L1 and L2 regularization. For each training set in your 5-\n",
    "fold cross validation, use part of it as a validation set to try out different values of Î» to find the\n",
    "best trade off between the loss function and the regularizing term. Report the final average F1\n",
    "score on the test sets of the 5-fold cross validation and comment on whether regularization\n",
    "helped or not.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [86.96, 88.1, 84.76, 81.06, 86.2]\n",
      "Average F1: 85.416\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l1(0.01)],\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l1(0.01)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [86.23, 88.1, 84.74, 81.1, 86.89]\n",
      "Average F1: 85.412\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l2(0.01)],\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l2(0.01)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [86.96, 87.44, 84.04, 82.58, 86.2]\n",
      "Average F1: 85.444\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l1_l2(0.01)],\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l1_l2(0.01)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: [89.8, 90.98, 86.78, 83.97, 91.99]\n",
      "Average F1: 88.704\n"
     ]
    }
   ],
   "source": [
    "layer_info={\"layers\":[\n",
    "    [15, tf.nn.relu, None ],\n",
    "    [15, tf.nn.relu, None ]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "model_v2 = create_model_v2(layer_info)\n",
    "train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different lambda values for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1.0\n",
      "F1 score: [35.21, 37.84, 36.41, 34.6, 34.29]\n",
      "Average F1: 35.670\n",
      "Lambda: 0.1\n",
      "F1 score: [35.21, 37.84, 36.41, 34.6, 34.29]\n",
      "Average F1: 35.670\n",
      "Lambda: 0.010000000000000002\n",
      "F1 score: [86.96, 88.1, 84.76, 81.84, 86.2]\n",
      "Average F1: 85.572\n",
      "Lambda: 0.0010000000000000002\n",
      "F1 score: [86.96, 87.39, 84.76, 81.1, 86.14]\n",
      "Average F1: 85.270\n",
      "Lambda: 0.00010000000000000002\n",
      "F1 score: [86.96, 87.39, 84.03, 81.1, 85.4]\n",
      "Average F1: 84.976\n",
      "Lambda: 1.0000000000000003e-05\n",
      "F1 score: [87.68, 88.1, 84.76, 81.84, 86.14]\n",
      "Average F1: 85.704\n",
      "Lambda: 1.0000000000000004e-06\n",
      "F1 score: [86.95, 88.1, 84.76, 81.84, 86.14]\n",
      "Average F1: 85.558\n",
      "Lambda: 1.0000000000000004e-07\n",
      "F1 score: [86.96, 88.1, 84.76, 80.35, 85.4]\n",
      "Average F1: 85.114\n",
      "Lambda: 1.0000000000000005e-08\n",
      "F1 score: [87.68, 87.33, 84.76, 81.1, 85.4]\n",
      "Average F1: 85.254\n",
      "Lambda: 1.0000000000000005e-09\n",
      "F1 score: [86.96, 87.39, 84.76, 81.84, 86.14]\n",
      "Average F1: 85.418\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _lambda = 0.1**i\n",
    "    print(\"Lambda: {}\".format(_lambda))\n",
    "    layer_info={\"layers\":[\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l1_l2(_lambda)],\n",
    "    [15, tf.nn.relu, tf.keras.regularizers.l1_l2(_lambda)]\n",
    "           ],\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"verbose\": 0\n",
    "           }\n",
    "    model_v2 = create_model_v2(layer_info)\n",
    "    train_with_kfold(model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "  \n",
    "    if verbose:\n",
    "        print('Network configuration ',neuronCountInEachLayer)\n",
    "    model.add(tf.keras.layers.Dense(neuronCountInEachLayer[0], input_dim=13, activation = activationFuncEachLayer[0], kernel_regularizer=regularizerFunc)) # First Layer\n",
    "    \n",
    "    for x in range(1, depthOfNetwork-1):\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(neuronCountInEachLayer[x], activation = activationFuncEachLayer[x],kernel_regularizer=regularizerFunc))         # Second layer onwards\n",
    " \n",
    "    model.add(tf.keras.layers.Dense(neuronCountInEachLayer[depthOfNetwork-1], activation = activationFuncEachLayer[depthOfNetwork-1]))  # Output layer\n",
    "    \n",
    "    model.compile(loss = lossFunction , optimizer = 'adam' , metrics = ['accuracy'] ) \n",
    "        \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "def evaluateTheModel(verbose=False):\n",
    "    n_split=5\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index,test_index in StratifiedKFold(n_split).split(X, y):      # StratifiedKFold, KFold\n",
    "        x_train,x_test=X[train_index],X[test_index]\n",
    "        y_train,y_test=y[train_index],y[test_index]\n",
    "\n",
    "        model=create_model(verbose)\n",
    "        model.fit(x_train, y_train,epochs=100, verbose=0)\n",
    "        evaluationMetrics = model.evaluate(x_test,y_test, verbose=0)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Model evaluation ',evaluationMetrics)   # This returns metric values for the evaluation\n",
    "\n",
    "        y_pred = np.where(model.predict(x_test) > 0.5, 1, 0)\n",
    "        print(model.predict(x_test))\n",
    "        f1 = f1_score(y_test, y_pred , average=\"macro\")\n",
    "\n",
    "        if verbose:\n",
    "            print('F1 score is ', f1)\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthOfNetwork = 2\n",
    "neuronCountInEachLayer = [2, 1]                                 # try different depth and width\n",
    "activationFuncEachLayer = ['sigmoid', 'sigmoid']            # try values relu, sigmoid, talh\n",
    "lossFunction = 'binary_crossentropy'                                # try values binary_crossentropy, mean_squared_error\n",
    "regularizerFunc = tf.keras.regularizers.l2(0)                       # try l1 and l2 with different lambda\n",
    "\n",
    "evaluateTheModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
